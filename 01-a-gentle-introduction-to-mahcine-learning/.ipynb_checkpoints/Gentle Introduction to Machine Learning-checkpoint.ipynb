{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A very gentle introduction to machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will just get a very gentle introduction to the machine learning or maybe <b>introduction of introduction of machine learning</b> using most commonly used libraries in Python for machine learning. We will basically look at the three main classification algorithms and their scores.\n",
    "<ul>\n",
    "    <li>Logistic Regression LR</li>\n",
    "    <li>KNeighborsClassifier KNN</li>\n",
    "    <li>Support Vector Machine SVC</li>\n",
    "</ul>\n",
    "\n",
    "This notebook is more intended to make you comfortable using the syntax of these algorithms (i.e perameters, different utility funcitons and how train and test splits are performed etc). We will be using a very classic dataset for our practice in machine learning which you probably should have guessed if you have ever done machine learning <b>iris dataset</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import pandas \n",
    "import sklearn\n",
    "\n",
    "print (\"Python: {}\".format(sys.version));\n",
    "print (\"Scipy: {}\".format(scipy.__version__))\n",
    "print (\"numpy: {}\".format(np.__version__))\n",
    "print (\"matplotlib: {}\".format(matplotlib.__version__))\n",
    "print (\"pandas: {}\".format(pandas.__version__))\n",
    "print (\"sklean: {}\".format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "names = [\"sepal-length\",\"sepal-width\",\"petal-length\",\"petal-width\",'class']\n",
    "dataset = pandas.read_csv(url,names=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at the data <a href=\"https://archive.ics.uci.edu/ml/datasets/iris\" target=\"_blank\">here</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>dataset</b> is an object of type <b>DataFrame</b> implemented in <b>pandas</b>. It orgranises the data in much simpler fashion. <b>DataFrame</b> or (<b>df</b> for short) is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet. It is generally the most commonly used pandas object. Following are some of the methods used to get a quick look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution (by class)\n",
    "print (dataset.groupby(\"class\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_matrix(dataset,figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data\n",
    "array = dataset.values #This will convert the pandas dataframe object to np(numpy) array\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "test_size = 0.20\n",
    "seed = 7 \n",
    "X_train,X_test,y_train,y_test = model_selection.train_test_split(X,Y,test_size= test_size,random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test option and evaluation metric\n",
    "scoring = \"accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating List of classifiers\n",
    "Now we are going to create the list classifiers for our classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append((\"LR\",LogisticRegression()))\n",
    "models.append((\"KNN\",KNeighborsClassifier()))\n",
    "models.append((\"SVM\",SVC()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print (model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Folds as per official docs\n",
    "K-Folds cross-validator\n",
    "Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default).\n",
    "<br>\n",
    "Each fold is then used once as a validation while the k - 1 remaining folds form the training set.\n",
    "## cross_val_score \n",
    "cross_val_score is used to evaluate the score by cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "names = []\n",
    "print (\"Type   MEAN     Std\")\n",
    "for name,model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10,random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model,X_train,y_train,scoring=scoring,cv=kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s:   %0.3f    (%0.5f)\" % (name,cv_results.mean(),cv_results.std())\n",
    "    print (msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions on test dataset\n",
    "for name,model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print (name)\n",
    "    print(accuracy_score(y_test,predictions))\n",
    "    print (classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here ends our very first tutorial to machine learning. I suggest you writing this code by yourself to get complete understanding. Under stand each and every complex "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
